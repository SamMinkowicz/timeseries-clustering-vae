{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to manage all useful information and data in these recordings more effectively, I created a class structure called `cage_data`. Each `.pkl` file in the folder `continuous` contains one `cage_data` object, corresponding to one of the 15-minute long recording files. For some practical reasons, we have a 2-second long pause between every two adjacent 15-minute long recording files.\n",
    "\n",
    "To read those `.pkl` files, first you need to have the codes defining the `cage_data` object in your path. You can find those codes in this [repo](https://github.com/limblab/cage_data). Clone it to your local machine, and simply add it to your path like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch, os, sys\n",
    "# Change this path to be wherever your `cage_data` directory is\n",
    "sys.path.append('/home/andrew_work/nu/miller_lab_work/cage_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cage_data\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load one file as an example\n",
    "\n",
    "Data are stored in the variable `my_cage_data`, an instance of the `cage_data` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /home/andrew_work/nu/miller_lab_work/Pop01-06_18_2021/20210618_Pop_Cage_001.pkl is going to be loaded\n",
      "This is a non-sorted file\n",
      "EMG filtered? -- False\n",
      "EMG filtered? -- False\n",
      "Cortical data cleaned? -- False\n",
      "Data binned? -- True\n",
      "Spikes smoothed? -- True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = '/home/andrew_work/nu/miller_lab_work/Pop01-06_18_2021/'\n",
    "file_name = '20210618_Pop_Cage_001.pkl'\n",
    "print('The file %s is going to be loaded'%(data_path + file_name))\n",
    "with open ( data_path + file_name, 'rb' ) as fp:\n",
    "    my_cage_data = pickle.load(fp)\n",
    "my_cage_data.pre_processing_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Some basic information about the file just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 95 cortical channels\n",
      "There are 16 EMG channels\n",
      "The raw EMG signals are sampled at 2011.061 Hz\n",
      "There are 113 behavior segments in this file\n",
      "The length of this file is 900.226 seconds\n",
      "Spikes and EMGs are binned or downsampled with 0.03 seconds time bins\n"
     ]
    }
   ],
   "source": [
    "print('There are %d cortical channels'%(len(my_cage_data.spikes)))\n",
    "print('There are %d EMG channels'%(len(my_cage_data.EMG_diff)))\n",
    "print('The raw EMG signals are sampled at %.3f Hz'%(my_cage_data.EMG_fs))\n",
    "print('There are %d behavior segments in this file'%(len(my_cage_data.behave_tags['tag'])))\n",
    "print('The length of this file is %.3f seconds'%(my_cage_data.EMG_timeframe[-1]))\n",
    "print('Spikes and EMGs are binned or downsampled with %.2f seconds time bins'%(my_cage_data.binned['timeframe'][1]-my_cage_data.binned['timeframe'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 How to get raw EMGs?\n",
    "\n",
    "The raw EMGs are acquired by DSPW wireless system with an Intan RHD2132 frontend. Since the channels on RHD2132 are all single-ended, we do software differential after getting the signals. Therefore, here the raw EMGs are stored in a field called `EMG_diff`.\n",
    "\n",
    "More specifically, `EMG_diff` is an attribute of the `cage_data` class, and could be accessed by calling:\n",
    "* raw_EMGs = my_cage_data.EMG_diff\n",
    "\n",
    "And the sampling frequency of the raw EMGs could be obtained by calling:\n",
    "* fs_raw_EMG = my_cage_data.EMG_fs\n",
    "\n",
    "The time frame of the raw EMGs could be obtained by calling:\n",
    "* raw_EMG_timeframe = my_cage_data.EMG_timeframe\n",
    "\n",
    "The names of each EMG channel could be got by:\n",
    "* EMG_names = my_cage_data.EMG_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 channels, and each channel has 1810409 time samples\n",
      "The raw EMG signals are sampled 2011.061 Hz\n"
     ]
    }
   ],
   "source": [
    "raw_EMGs = my_cage_data.EMG_diff\n",
    "print('There are %d channels, and each channel has %d time samples'%(len(raw_EMGs), len(raw_EMGs[0])))\n",
    "\n",
    "raw_EMG_timeframe = my_cage_data.EMG_timeframe\n",
    "\n",
    "fs_raw_EMG = my_cage_data.EMG_fs\n",
    "print('The raw EMG signals are sampled %.3f Hz'%(fs_raw_EMG))\n",
    "\n",
    "EMG_names = my_cage_data.EMG_names  # these are abbreviated names for muscles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `raw_EMGs` is a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 How to get raw spike timings?\n",
    "\n",
    "Raw spike timings are stored with the attribute `spikes`, and could be got like this:\n",
    "* spike_timing = my_cage_data.spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_timing = my_cage_data.spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `spike_timing` is a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 How to get binned / downsampled spike counts and filtered EMG envelops? \n",
    "\n",
    "The binned data is stored with another attribute named `binned`. It is a dictionary, and could be accessed like this:\n",
    "* binned = my_cage_data.binned\n",
    "\n",
    "There are 4 fields in this dictionary:\n",
    "* spikes: binned spike counts\n",
    "* filtered_EMG: EMG envelops been rectified, filtered and downsampled\n",
    "* FSR_data: the data from force sensitive resistors inside the plastic cage, only meaningful for power grasping\n",
    "* timeframe: the common time frame for the 3 types of data above\n",
    "\n",
    "Data in the files we are using now are binned with 50 ms time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['timeframe', 'spikes', 'filtered_EMG', 'FSR_data'])\n",
      "[3.750000e-02 6.250000e-02 8.750000e-02 ... 9.001625e+02 9.001875e+02\n",
      " 9.002125e+02]\n"
     ]
    }
   ],
   "source": [
    "print(my_cage_data.binned.keys())\n",
    "\n",
    "# To get the binned spike counts\n",
    "binned_spike_counts = my_cage_data.binned['spikes']\n",
    "\n",
    "# To get the rectified, filtered and downsampled EMGs\n",
    "filtered_EMG = my_cage_data.binned['filtered_EMG']\n",
    "\n",
    "# To get the time frame of the binned data\n",
    "timeframe = my_cage_data.binned['timeframe']\n",
    "\n",
    "# print(np.array(filtered_EMG).shape)\n",
    "print(my_cage_data.binned['timeframe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 How to get the information about the monkey's behavior?\n",
    "The start time and end time and the type of the behaivor of each behavior segment are stored with the attribute `behave_tags`, which is also a dictionary. It has 3 fields, and the names of them are self-explanatory:\n",
    "\n",
    "* start_time\n",
    "* end_time\n",
    "* tag\n",
    "\n",
    "For example, check the 74th behavior segment in this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the 0th behavior segment, the monkey was doing 'crawling'\n",
      "The start time of the 0th behavior segment is at the 78.811 second\n",
      "The end time of the 0th behavior segment is at the 80.743 second\n"
     ]
    }
   ],
   "source": [
    "N = 0\n",
    "print('During the %dth behavior segment, the monkey was doing \\'%s\\''%(N, my_cage_data.behave_tags['tag'][N]))\n",
    "print('The start time of the %dth behavior segment is at the %.3f second'%(N, my_cage_data.behave_tags['start_time'][N]))\n",
    "print('The end time of the %dth behavior segment is at the %.3f second'%(N, my_cage_data.behave_tags['end_time'][N]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the index of the first behavior segment is \"_0_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the behavior segments stored in the files I shared last time are generated by the function below. But since we already have them, further introduction is not needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_segs = my_cage_data.get_all_data_segment(requires_raw_EMG = True, requires_spike_timing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Autocorrelation Analysis for Finding Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOU DON'T NEED TO RUN THIS - See where autocorrelation drops off in order to pick a sequence length \n",
    "%matplotlib notebook\n",
    "muscles = np.array(filtered_EMG)[:10000]\n",
    "\n",
    "from scipy.stats import pearsonr, zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auto_corrs = 0\n",
    "muscles = muscles - np.mean(muscles, axis=0)\n",
    "\n",
    "for i, muscle in enumerate(muscles):\n",
    "    auto_corrs += (np.correlate(muscle, muscle, mode=\"full\")) / len(muscle)\n",
    "auto_corrs /= 16\n",
    "plt.plot(auto_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Converting to Recurrent VAE Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cage data objects for each of the files of interest - if you have / want more, just add them to the list\n",
    "dir_path = '/home/andrew_work/nu/miller_lab_work/PopEMG/labeled_cage_data_objects/'\n",
    "cage_data_filenames = [dir_path+'20210618_Pop_Cage_001.pkl',\n",
    "                       dir_path+'20210618_Pop_Cage_003.pkl',\n",
    "                       dir_path+'20210618_Pop_Cage_004.pkl']\n",
    "cage_data_objs = []\n",
    "for fn in cage_data_filenames:\n",
    "    with open (fn, 'rb' ) as fp:\n",
    "        my_cage_data = pickle.load(fp)\n",
    "        cage_data_objs.append(my_cage_data.get_all_data_segment(requires_raw_EMG = True, \n",
    "                                                                requires_spike_timing = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired sequence length\n",
    "SEQ_LEN = 30\n",
    "\n",
    "# Create behavior class dict for mapping - these are all the currently labeled behaviors they gave us\n",
    "bhvs = {'sitting_still': np.array([0]),\n",
    "        'crawling': np.array([1]), \n",
    "        'pg': np.array([2]),\n",
    "        'grooming': np.array([3]),\n",
    "        'no_behavior': np.array([-1])}\n",
    "\n",
    "# Create inverse mapping for debugging\n",
    "inv_bhvs = {v: k for k, v in bhvs.items()}\n",
    "\n",
    "# Sort all behavior segments by their start timestep - NOT EVERY EMG HAS A BEHAVIOR ASSIGNED TO IT \n",
    "behavior_segs = sorted(behavior_segs, key=lambda k: k['timeframe'][0])\n",
    "\n",
    "# To get the rectified, filtered and downsampled EMGs\n",
    "filtered_EMG = my_cage_data.binned['filtered_EMG']\n",
    "filtered_EMG = np.array(filtered_EMG).T\n",
    "\n",
    "# To get the time frame of the binned data\n",
    "timeframe = my_cage_data.binned['timeframe']\n",
    "rem = timeframe.shape[0] % SEQ_LEN\n",
    "time_seqs = np.array(timeframe)[:-rem].reshape(-1, 30)\n",
    "\n",
    "# Create list of tuples (time_stamp, behavior)\n",
    "emg_lbls = []\n",
    "for i, time in enumerate(timeframe):\n",
    "    curr_time_tup = None\n",
    "    for seg in behavior_segs:\n",
    "        if time >= seg['timeframe'][0] and time <= seg['timeframe'][-1]:\n",
    "            curr_emg_tup = np.concatenate((bhvs[seg['label']], filtered_EMG[i]))\n",
    "            break\n",
    "        else:\n",
    "            curr_emg_tup = np.concatenate((bhvs['no_behavior'], filtered_EMG[i]))\n",
    "    emg_lbls.append(curr_emg_tup)\n",
    "\n",
    "# Create array where timestamp is first dimension and behavior class is second\n",
    "emg_lbls = np.array(emg_lbls)\n",
    "\n",
    "# Chop off last last frames so we can evenly divide\n",
    "rem = emg_lbls.shape[0] % SEQ_LEN\n",
    "emg_lbls = emg_lbls[:-rem, :]\n",
    "emg_lbls = emg_lbls.reshape(-1, SEQ_LEN, 17)\n",
    "\n",
    "# Find the most represented class in each sequence\n",
    "out = []\n",
    "overlap_idx = int(SEQ_LEN * 0.5)\n",
    "for i, emg_seq in enumerate(emg_lbls):\n",
    "    # Append indexed sequence with its class\n",
    "    seq_class = stats.mode(emg_seq[:,0])[0]\n",
    "    flat_emg = emg_seq[:,1:].reshape(-1)\n",
    "    out.append(np.concatenate((seq_class, flat_emg)))\n",
    "    \n",
    "    # Add 50% time overlap array to output\n",
    "    if i < len(emg_lbls) - 1:\n",
    "        overlap = np.concatenate((emg_seq[overlap_idx:, :], emg_lbls[i][:overlap_idx, :]), axis=0)\n",
    "        overlap_class = stats.mode(overlap[:,0])[0]\n",
    "        flat_overlap = overlap[:,1:].reshape(-1)\n",
    "        out.append(np.concatenate((overlap_class, flat_overlap)))\n",
    "\n",
    "out = np.array(out)\n",
    "\n",
    "# Change the path here to be wherever you want to save the data to\n",
    "np.savetxt('/home/andrew_work/nu/miller_lab_work/experiments/timeseries-clustering-vae/data/limb_lab_TRAIN', out, delimiter=',')\n",
    "np.savetxt('/home/andrew_work/nu/miller_lab_work/experiments/timeseries-clustering-vae/data/limb_lab_TEST', out, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 A function to filter the raw EMGs\n",
    "A number of useful functions are designed as the methods of the `cage_data` behavior. This one is used to filter the raw EMGs and then to get the EMG envelops\n",
    "* EMG_filtering(self, f_Hz), `f_Hz` is the corner frequency of the low pass filter to get the envelops\n",
    "\n",
    "There is no return from this function. This function will update (or create if not existing) the attribute `filtered_EMG`.\n",
    "\n",
    "Note that here `filtered_EMG` is an attribute of the `cage_data` class, which is different from the field `filtered_EMG` under the attribute `binned`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All EMG channels have been filtered.\n"
     ]
    }
   ],
   "source": [
    "# Filtering the raw EMGs with a 15 Hz low-pass filter and to get the rectified envelops, all done with this function\n",
    "my_cage_data.EMG_filtering(15)\n",
    "EMG_envelops = my_cage_data.filtered_EMG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As no downsampling or binning is performed here, the obtained EMG envelops are still have the same sampling frequency as the raw EMGs, which is `my_cage_data.EMG_fs` as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 A function to bin the spikes and downsample the EMGs\n",
    "Although the files shared in Box are all binned with 50 msec bins, you can still use this function to re-bin the data. After doing this, the items in the attribute `binned` will be updated.\n",
    "* bin_data(self, bin_size, mode = 'center')\n",
    "\n",
    "`bin_size` is the size of the bin in seconds. `mode` is the way to align the time bins, `center` is OK, and another option is `left`\n",
    "\n",
    "This function will not return a value either. It only update the attribute `binned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bin_size = 0.02 # 20 msec\n",
    "my_cage_data.bin_data(new_bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the function `save_to_pickle` like this:\n",
    "* my_cage_data.save_to_pickle(save_path, save_file_name)\n",
    "\n",
    "You could save the instance you updated.\n",
    "\n",
    "If the `my_cage_data` instance is occupying too much memory, just delete it like this\n",
    "* del(my_cage_data)\n",
    "\n",
    "You could pull different types of data from it and save them individually before deleting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_EMG_arr = np.array(filtered_EMG)\n",
    "fig2 = plt.figure(constrained_layout=True)\n",
    "spec2 = gridspec.GridSpec(ncols=2, nrows=8, figure=fig2)\n",
    "    \n",
    "f2_ax1 = fig2.add_subplot(spec2[0, 0])\n",
    "f2_ax1.plot()\n",
    "f2_ax2 = fig2.add_subplot(spec2[1, 0])\n",
    "f2_ax3 = fig2.add_subplot(spec2[2, 0])\n",
    "f2_ax4 = fig2.add_subplot(spec2[3, 0])\n",
    "f2_ax1 = fig2.add_subplot(spec2[4, 0])\n",
    "f2_ax2 = fig2.add_subplot(spec2[5, 0])\n",
    "f2_ax3 = fig2.add_subplot(spec2[6, 0])\n",
    "f2_ax4 = fig2.add_subplot(spec2[7, 0])\n",
    "\n",
    "f3_ax1 = fig2.add_subplot(spec2[0, 1])\n",
    "f3_ax2 = fig2.add_subplot(spec2[1, 1])\n",
    "f3_ax3 = fig2.add_subplot(spec2[2, 1])\n",
    "f3_ax4 = fig2.add_subplot(spec2[3, 1])\n",
    "f3_ax1 = fig2.add_subplot(spec2[4, 1])\n",
    "f3_ax2 = fig2.add_subplot(spec2[5, 1])\n",
    "f3_ax3 = fig2.add_subplot(spec2[6, 1])\n",
    "f3_ax4 = fig2.add_subplot(spec2[7, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
